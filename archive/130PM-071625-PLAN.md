# Consolidated Rectification Plan (130PM-071625-PLAN.md)

## 1. Overview

This document provides a comprehensive technical plan to rectify all identified issues within the GBStudio Automation Hub. It serves as a single source of truth, documenting actions already completed and detailing the precise steps for all future work. The goal is to produce a stable, robust, and well-documented application ready for feature expansion.

---

## 2. Phase 1: Infrastructure & Environment Synchronization (Completed)

This phase addressed the critical desynchronization between the local file system and the Docker environment, which was the root cause of all major application crashes.

### 2.1. Problem Analysis (What was wrong)

*   **Stale Backend Code:** The `backend` service in `docker-compose.yml` was missing a volume mount for `./scripts`. This meant only the code from the initial `docker build` was being used, and any subsequent bug fixes in local Python files were ignored, causing the `TypeError: log_chat_message()` crash.
*   **Incorrect Volume Sharing:** The `backend` service was attempting to use a local bind mount (`./comfyui_output`) while the `comfyui` service was correctly using a Docker-managed named volume (`comfyui_output`). The two services could not see each other's files, which would have caused the asset approval workflow to fail.
*   **Fatal Docker Build Error:** The `Dockerfile` located in the local `~/ComfyUI` directory was misconfigured. It was attempting to pull a non-existent base image (`FROM comfyanonymous/comfyui:latest`) instead of building from the local source files. This caused the `docker-compose build` command to fail.
*   **Disk Space Catastrophe:** The misconfigured `Dockerfile` lacked a `.dockerignore` file. This caused the build process to copy the entire multi-gigabyte `~/ComfyUI/models` directory into the image, consuming all available disk space.

### 2.2. Actions Taken (What has been done)

1.  **Corrected `docker-compose.yml`:** Modified the `backend` service to use the named volume `comfyui_output`, ensuring it shares the same output directory as the `comfyui` service.
2.  **Created `.dockerignore`:** Instructed the user to manually create a `.dockerignore` file in the `~/ComfyUI` directory to exclude the `models/` and `output/` folders from the build context. This permanently solved the disk space issue.
3.  **Corrected `ComfyUI/Dockerfile`:** Provided the user with a new, correct `Dockerfile` content that builds from a standard `python:3.11` base image and copies the local source files, rather than attempting to pull a non-existent image.
4.  **Pruned Docker System:** Executed `docker system prune -af` to immediately reclaim the disk space lost to the failed build.
5.  **Rebuilt & Restarted Services:** Successfully executed `docker-compose build --no-cache` and `docker-compose up -d`.

### 2.3. Current Status

The entire application stack is now running in a stable, correctly configured, and synchronized environment. The backend is running the latest code, and all services can communicate and share files as intended.

---

## 3. Phase 2: Codebase Hardening & Best Practices (Next Steps)

This phase will improve the resilience and maintainability of the Python code.

### 3.1. Action: Refine Backend Error Handling

*   **Problem:** The `call_ollama_agent` function uses a generic `except Exception`, which makes debugging difficult by hiding the specific nature of a failure.

*   **Current Broken Code (`scripts/main.py`):**
    ```python
    # This is bad practice. It catches everything, so we don't know if it was
    # a connection error, a server error, or a problem with the response format.
    except Exception as e:
        print(f"Error calling agent: {e}")
        return {"error": str(e)}
    ```

*   **Next Action:** I will replace the generic exception with specific handlers for connection errors, API errors, and JSON parsing errors. This provides clearer logs and more useful error messages to the user.

*   **Proposed New Code (`scripts/main.py`):**
    ```python
    try:
        async with aiohttp.ClientSession() as session:
            async with session.post(settings.ollama_api_url, json=payload, timeout=300) as response:
                response.raise_for_status() # Raises an exception for 4xx/5xx responses
                response_text = await response.text()
                ollama_payload = json.loads(response_text) # Can raise json.JSONDecodeError
                model_response_str = ollama_payload.get("response", "")
                return {"response": model_response_str, "type": "conversation"}
    except aiohttp.ClientConnectorError as e:
        logging.error(f"Ollama Connection Error: {e}")
        return {"error": "Could not connect to the Ollama service."}
    except aiohttp.ClientResponseError as e:
        logging.error(f"Ollama API Error: Status {e.status}, Message: {e.message}")
        return {"error": f"Ollama API returned an error: {e.message}"}
    except json.JSONDecodeError:
        logging.error(f"Ollama response is not valid JSON: {response_text}")
        return {"error": "Failed to parse the response from the Ollama agent."}
    except Exception as e:
        logging.error(f"An unexpected error in call_ollama_agent: {e}", exc_info=True)
        return {"error": "An unexpected error occurred while communicating with the agent."}
    ```

### 3.2. Action: Standardize Database Logging

*   **Problem:** The `conversations` table lacks an `agent_name` column, making it impossible to track which agent was involved in a given interaction. This was the root cause of the original `TypeError` crash.

*   **Next Action:** I will implement a robust, three-part fix to add this crucial context to the database.

*   **Proposed Code Changes:**

    1.  **Safely alter the database schema (`scripts/database.py`):**
        ```python
        def initialize_database():
            """Initializes the database and creates/alters tables as needed."""
            conn = get_db_connection()
            if conn is None: return
            try:
                with conn:
                    # ... (existing CREATE TABLE statements) ...
                    
                    # Add agent_name column to conversations if it doesn't exist
                    cursor = conn.execute("PRAGMA table_info(conversations)")
                    columns = [row['name'] for row in cursor.fetchall()]
                    if 'agent_name' not in columns:
                        conn.execute("ALTER TABLE conversations ADD COLUMN agent_name TEXT;")
                        logging.info("Added 'agent_name' column to 'conversations' table.")
            finally:
                conn.close()
        ```

    2.  **Update the logging function to accept the new data (`scripts/database.py`):**
        ```python
        def log_chat_message(agent_name: str, user_message: str, agent_response: str):
            """Logs a user message and an agent's response to the database."""
            conn = get_db_connection()
            if conn is None: return
            try:
                with conn:
                    conn.execute(
                        "INSERT INTO conversations (agent_name, timestamp, user_message, agent_response) VALUES (?, ?, ?, ?)",
                        (agent_name, datetime.now().isoformat(), user_message, agent_response)
                    )
                logging.info(f"Successfully logged chat message for agent '{agent_name}'.")
            finally:
                conn.close()
        ```

    3.  **Update the calling code to provide the new data (`scripts/main.py`):**
        ```python
        # In the chat_with_agent endpoint
        background_tasks.add_task(
            log_chat_message,
            agent_name=agent_name, # This parameter is now required
            user_message=chat_message.message,
            agent_response=json.dumps(response_data)
        )
        ```

---

## 4. Phase 3: Documentation & Project Management Cleanup (Upcoming)

This phase will clean up project clutter and create clear, accurate documentation for future development.

### 4.1. Action: Consolidate Planning Documents

*   **Problem:** Multiple conflicting `PLAN.md` files create confusion.
*   **Next Action:** I will create a single, authoritative `ROADMAP.md` file that synthesizes the goals from all previous plans into a clear, forward-looking document.

### 4.2. Action: Overhaul `README.md`

*   **Problem:** The current `README.md` is outdated and does not reflect the project's Docker-based architecture or functionality.
*   **Next Action:** I will replace the entire file with a modern, accurate guide that explains the architecture and provides simple, correct setup instructions.
